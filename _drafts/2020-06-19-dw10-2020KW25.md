---
layout: post
title: >-
    Discoveries Weekly No. 10 (June 15-22, 2020)
category: DiscoveryWeekly
---

Here are some discoveries that fascinate me this week.

* TOC
{:toc}

## Biology

### Physiology, pathology, and therapeutical applications of TREM2

[Deczkowska *et
al.*](https://www.cell.com/cell/fulltext/S0092-8674(20)30565-1) explores the
TREM2 receptor pathway as a major pathology-induced immune signalling mediator.

### Single-cell and secretome atlas of human enteroendocrine cells

[Beumer *et al*](https://www.cell.com/cell/fulltext/S0092-8674(20)30501-8)
reports transcriptomics profiling and secretome analysis of human
enteroendocrine cells in a human organoid biobank.

### DNA of neutrophil extracellular traps promotes cancer metastasis via CCDC25

Neutrophils are cells in the blood that are promptly (within minutes) and
strongly activated upon infection by microorganisms. They have a very special
trick to clear microorganisms: they can secret neutrophil extracellular traps,
which consist of chromatin DNA filaments that are coated with proteins that are
usually stored in granules in the cells. These traps made of DNA and proteins
coat and lock the microorganisms so that the whole thing can be cleared by
phagocytotic cells like macrophages.

The traps, alas, seem not only provide advantage to the host, though. [Yang *et
al.*](https://www.nature.com/articles/s41586-020-2394-6) reported on *Nature*
that they found abundant such traps in the metastases, and the traps in the
serum can predict the occurrence of metastases. They report that DNA in the
traps, known as neutrophil-extracellular-trap (NET) DNA, attract cancer cells
rather than acting only as a &lsquo;trap&rsquo;. They found that the protein
[CCDC25](https://www.nature.com/articles/s41586-020-2394-6) (coiled-coil domain
containing 25, GeneID 55246) acts as a NET-DNA sensor, which can act the
ILK-beta-parvin pathway to enhance cell motility.

They showed that NET-mediated metastasis can be abrogated in CCDC25-knockout
cells. The results suggest that targeting CCDC25 may be a therapeutic strategy
for the prevention of cancer metastasis.

A [News and
Views](https://www.nature.com/articles/d41586-020-01672-3) article by Emma Nolan
and Ilaria Malanchi summarizes the findings.

### Notch3 drives synovial fibrosis and arthritis

The synovium, also known as the synovial membrane, is a connective tissue that
lines the inner surface of capsules of synovial joints and tendon sheath. It is
a mesenchymal tissue composed mainly of fibroblasts that surrounds the joints.

In rheumatoid arthritis (RA), the synovial tissue gets enlarged substantially
(known as *hyperplasia*) and becomes inflamed and invasive so that it can
destroy the joint.

[Wei *et al.*](https://www.nature.com/articles/s41586-020-2222-z) reported on
*Nature* that [NOTCH3](https://www.ncbi.nlm.nih.gov/gene/4854) (Notch receptor
3, GeneID 4854) signalling drives differentiation of fibroblasts that express
the CD90 protein, product of the [THY1](https://www.ncbi.nlm.nih.gov/gene/7070)
(Thy-1 cell surface antigen, GeneID 7070) gene. They used single-cell sequencing
and synovial tissue organoids to demonstrate that NOTCH3 signalling drives both
transcriptional and spatial gradients, spreading out (`emanating` as the authors
said) from vascular endothelial cells outwards in fibroblasts.

NOTCH3 itself and target genes of the Notch signaling pathways are upregulated
in synovial fibroblasts from patients of active rheumatoid arthritis. The link
between NOTCH3 and inflammatory arthritis is supported by mouse models. The
authors argue that synovial fibroblasts possess a positional identity which is
regulated by Notch signalling derived from endothelial cells. They suggest that
the crosstalk between endothelial cells and fibroblasts via Notch signalling
underlying inflammation and pathology in inflammatory arthritis. The results,
the authors reckoned, provide a molecular basis by which stromal cells, defined
as connective tissue cells of any organ, which usually include fibroblasts and
pericytes, can be therapeutically targeted in rheumatoid arthritis by modulation
of NOTCH3 signalling.

The study identified JAG2 and DLL4, both ligands of Notch3 signalling, expressed
in both synovial tissue and synovial organoid (Figure 3A). The RNA-sequencing
data is available at [ImmPort](https://ww.immport.org) under accession code
SDY1599 for human studies, and at the Gene Expression Omnibus under accession
code [GSE145286](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE145286).
Intermediate data (UMAP projections and normalized counts) are available at the
[single-cell portal of the Broad
Institute](https://portals.broadinstitute.org/single_cell/study/SCP469). And the
code for data analysis is available on GitHub
[immunogenomics/notch](http://github.com/immunogenomics/notch).

## Programming

### Submitting Snakemake jobs to Slurm

See my other blog post [Submitting Snakemake jobs to Slurm]({% post_url
2020-06-16-Snakemake-with-slurm %}).

### SQLite as a file format

[SQLite as an application file
format](https://www.sqlite.org/appfileformat.html) was a hot thread on
[HackerNews](https://news.ycombinator.com/item?id=18754634).

The HDF5 file format ([website of the HDF group](https://www.hdfgroup.org/), or
[Wikipedia on HDF files](https://www.hdfgroup.org/)) may be an alternative
option, especially for scientific data.

### Other programming tricks that I learned

* Often we have a list of strings in a tab-delimited file, like
    `S1,S2,S3,...,S10,...`, which we would like to sort by the numeric part of
    the string. The solution is to use `sort -V`. `-V` or `--version-sort`
    performs natural sort of (version) numbers within text. Source:
    [nitin@StackOverflow](https://stackoverflow.com/questions/16945134/bash-sort-list-of-strings-by-number-at-the-end).
* `gensub` in `awk` can perform pattern matching and back reference. Below is an
    example. Source: [GNU manual of
    gawk](https://www.gnu.org/software/gawk/manual/html_node/String-Functions.html).

```bash
echo "S10_10" | awk '{
  a=gensub(/S(.+)_(.+)/, "\\1", "g");
  b=gensub(/S(.+)_(.+)/, "\\2", "g");
  print a,b;}'
## output: 10 10
```

* If files in a directory in Linux shows question marks `?` in every property
  when we use `ls` to list them, it may be that the permissions have gone wrong.
  The solution is to apply `chmod -R a+rX DIR_NAME` to the directory. Source:
  [StackOverflow](https://askubuntu.com/questions/243999/why-do-question-mark-characters-appear-when-changing-the-permissions-of-director).

## Statistics and machine learning

### Three classical approaches to hypothesis testing

There are three classical approaches to hypothesis testing in the frequentist
statistics. The oldest is the likelihood-ratio test, sometimes abbreviated as
&lsduo;LQT&rsduo;. It describes the goodness of fit of two statistical models
being considered on the ratio of their likelihoods, which is found either by
maximization over the entire parameter space, or either by imposing certain
constraints. The constraints, for instance, can be expressed as the null
hypothesis. If the constraints are supported by the data, the two likelihoods
should not differ by more than sampling error. Therefore, the likelihood-ratio
test tests whether the ratio of two likelihood values is significant from one.

The [Neyman-Pearson
lemma](https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma) states that
when we compare two models each of which has no unknown parameters, the
likelihood-ratio test is the most powerful test among all statistical tests.

The other two approaches are the score test (also known as &lsquo;Lagrange
multiplier test&rsquo;) and the Wald test, named after the Hungarian
mathematician Abraham Wald.

The score test evaluates constraints on the parameter to be estimated based on
the gradient of the likelihood function with respect to the parameter, which is
known as the *score*, evaluated at the hypothesized parameter value under the
null hypothesis. If the estimator is near the maximum of the likelihood
function, then the score should not differ from zero by more than sampling
error.

The Wald test in essence is based on the weighted
distance between the estimate and its hypothesized value under the null
hypothesis, where the weight is the precision of the estimate, namely the
reciprocal of the variance. So the form resembles closely that of a t-test.
Indeed, when testing a single parameter, the square root of the Wald statistic
can be understood as a (pseudo) t-ratio, which is, however, not actually
t-distributed except for the special case of linear regression.

The three approaches are asymptotically equivalent (all approaching the
chi-square distribution), though in the case of finite samples, the results can
differ strongly between the methods.

In Bayesian statistics, suppose that we have a prior distribution of a
parameter, which can be our intuition or prior knowledge, some data associated
with that parameter, and we wish to estimate (infer) the value of a parameter
given the prior distribution and the data. One can use the mode of the posterior
distribution, which is distribution of the parameter updated from the prior
model by the data, as the best guess of the parameter. The mode of the posterior
distribution is known as the Maximum a posteriori probability estimate, or
simply the *MAP estimate*.

If we have two hypotheses, we can choose the one with the highest posterior
probability. This is known as the *MAP hypothesis test*. See the course's
website of [Introduction to Probability, Statistics and Random
Processes](https://www.probabilitycourse.com/chapter9/9_1_8_bayesian_hypothesis_testing.php)
for mathematical details and examples of MAP hypothesis test. And see the blog
post by Jonny Brooks-Bartlett [*Probability concepts explained: Bayesian
inference for parameter
estimation*](https://towardsdatascience.com/probability-concepts-explained-bayesian-inference-for-parameter-estimation-90e8930e5348)
for graphical examples and more explanations.

But what happens that we have two competing hypotheses with strong difference in
complexity? Then we need to select among the models, following the principle of
Occam's Razor: *Use fewer things unless necessary*.

The mostly used Bayesian versions of model selection are Akaike information
criterion (AIC) and Bayesian information criterion. They both reward parameters
and models that maximize likelihood, while penalizing complex models.

### Other gems in statistics and machine learning

In [this Minitab Blog
Post](https://blog.minitab.com/blog/statistics-and-quality-data-analysis/what-are-degrees-of-freedom-in-statistics)
I found a clear explanation of the concept of *degree of freedom* (often abbreviated
as &lsquo;d.f.&rsduo) in the context of hat warning, one-sample t-test,
Chi-square test, and linear regression.

A relevant key concept to understand about degree of freedom is *constraint*. In
mathematics, a constraint is a condition of a problem that the solution must
satisfy. Say if we want to compare whether the average height of ten persons
equals 1.65m. We can use an one-sample test for it. The null hypothesis is that
the average height is indeed 1.65m (plus and minus sampling error), and the
alternative hypothesis is that the average is a different value.

So under the null hypothesis, the constraint is that the average height must be
1.65m, or the sum of the height of ten persons must be 16.5m. That means, the
height of nine persons can vary as they wish, but the last person's height must
be such a value that the mean (or the sum) matches the average value. That is
the constraint of our problem.

If this is clear, then the degree of freedom of an one-sample t-test is clear:
it is $ n-1 $ for a sample of $ n $ probes. By following the logic, we have
following rules

* The degree of freedom is $m+n-2$ for two-sample t-tests with two groups of
    sizes $m$ and $n$, respectively.
* The degree of freedom of a $2\times2$ table, used in a Chi-square test of
  independence, has a freedom of 1, because the row sum and column sum are
  constraints. For a table of size $m\timesn$, the degree of freedom is
  $(m-1)(n-1)$.
* The degree of freedom of a regression analysis is $n-p$, where $n$ is the
    number of data points to be regressed and $p$ is the number of parameters in
    the regression model.

More generally, in mathematics, degree of freedom can represent the number of
*dimensions* of the *domain* of a random vector, or the number of *free*
components, the number of components by knowing each we can fully determine the
vector. Any in a dynamic system, degree of freedom specifies the number of
independent ways the system can move, without violating any constraint imposed
on it.

## Other gems

* I wrote a short blog post [about time]({% post_url 2020-06-17-about-time
    %}).
* If you are impressed, touched, or fascinated by the author Wolfgang Herrndorf
    like I am, here is a website about him that may interest you
    [ueberwolfgang.de](https://www.ueberwolfgang.de)

### How to overcome a fear of heights

The Psyche magazine of Aeon, a online magazine of philosophy and culture,
published an interesting article on [how to overcome a fear of
heights](https://psyche.co/guides/how-to-overcome-a-fear-of-heights-step-by-careful-step)
by Poppy Brown.



